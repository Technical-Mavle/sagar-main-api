# In sagar-main-api/orchestrator_router.py

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
import os
import google.generativeai as genai
from google.generativeai.types import GenerationConfig, Tool, FunctionDeclaration

# --- NEW: Import functions directly from the backend router ---
from backend_router import discover_and_correlate_data, search_metadata, OrchestrationRequest

router = APIRouter()

# --- Load Environment Variables ---
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# --- Configure the Gemini Client ---
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=GEMINI_API_KEY)

# --- Pydantic Models ---
class PromptRequest(BaseModel):
    prompt: str = Field(..., example="What is the correlation between fish count and total ozone near India?")

# --- Gemini Function Calling Setup ---
discover_and_correlate_tool = Tool(
    function_declarations=[
        FunctionDeclaration(
            name="discover_and_correlate",
            description="Finds two datasets by their description, then runs a geospatial correlation analysis between a specific column from each.",
            parameters={
                "type": "object",
                "properties": {
                    "file1_id": {"type": "integer"}, "file2_id": {"type": "integer"},
                    "column1": {"type": "string"}, "column2": {"type": "string"},
                    "file1_lat_col": {"type": "string"}, "file1_lon_col": {"type": "string"},
                    "file2_lat_col": {"type": "string"}, "file2_lon_col": {"type": "string"}
                },
                "required": ["file1_id", "file2_id", "column1", "column2"]
            }
        )
    ]
)

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    tools=[discover_and_correlate_tool]
)

# --- API Endpoints ---
@router.post("/understand-and-execute")
async def understand_and_execute(request: PromptRequest, background_tasks: BackgroundTasks):
    """
    Takes a natural language prompt, uses Gemini to create an API call payload,
    and then directly calls the backend function to execute the analysis.
    """
    try:
        # 1. Call the search function directly to get context for the LLM
        available_datasets = await search_metadata()
        
        # 2. Construct a detailed prompt for the Gemini model
        context_prompt = f"""
        User prompt: "{request.prompt}"
        Available datasets: {available_datasets}
        Based on the user prompt and datasets, determine the parameters for the 'discover_and_correlate' function.
        Focus on file IDs and exact column names from the metadata. For fish count, use 'individualCount'. For ozone, use 'TO3'.
        For coordinates in tabular data, use 'decimalLatitude'/'decimalLongitude'. For coordinates in netcdf data, use 'lat'/'lon'.
        """
        
        # 3. Call the Gemini API
        response = await model.generate_content_async(
            context_prompt,
            generation_config=GenerationConfig(temperature=0)
        )
        
        # 4. Extract the function call generated by the model
        function_call = response.candidates[0].content.parts[0].function_call
        if not function_call or function_call.name != "discover_and_correlate":
            raise HTTPException(status_code=400, detail="Could not determine the correct action from the prompt.")
        
        api_parameters = dict(function_call.args)
        
        # 5. Call the backend function directly
        # Create an OrchestrationRequest object to ensure data types are correct
        backend_request = OrchestrationRequest(**api_parameters)
        return await discover_and_correlate_data(backend_request, background_tasks)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {str(e)}")